{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re\n",
    "import configparser\n",
    "from datetime import timedelta, datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, when, lower, isnull, year, month, dayofmonth, hour, weekofyear, dayofweek, date_format, to_date\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, DoubleType, LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The AWS key id and password are configured in a configuration file \"dl.cfg\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "# Reads and saves the AWS access key information and saves them in a environment variable\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "# OUTPUT = config['ETL']['OUTPUT_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder.config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.jars.packages\",\n",
    "                                        \"saurfang:spark-sas7bdat:2.0.0-s_2.11,org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read US Cities Demo dataset file\n",
    "demographics=spark.read.csv(\"us-cities-demographics.csv\", sep=';', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying Total Number of Records\n",
    "demographics.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Schema to verify that all the columns are in \"string\" format\n",
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cast_type(df, cols):\n",
    "    \"\"\"\n",
    "    Convert the types of the columns according to the configuration supplied in the cols dictionary in the format {\"column_name\": type}\n",
    "    \n",
    "    Args:\n",
    "        df (:obj:`SparkDataFrame`): Spark dataframe to be processed. \n",
    "            Represents the entry point to programming Spark with the Dataset and DataFrame API.\n",
    "        cols (:obj:`dict`): Dictionary in the format of {\"column_name\": type} indicating what columns and types they should be converted to\n",
    "    \"\"\"\n",
    "    for k,v in cols.items():\n",
    "        if k in df.columns:\n",
    "            df = df.withColumn(k, df[k].cast(v))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert numeric columns to the proper types: Integer and Double\n",
    "int_cols = ['Count', 'Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born']\n",
    "float_cols = ['Median Age', 'Average Household Size']\n",
    "demographics = cast_type(demographics, dict(zip(int_cols, len(int_cols)*[IntegerType()])))\n",
    "demographics = cast_type(demographics, dict(zip(float_cols, len(float_cols)*[DoubleType()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# demographics.printSchema()\n",
    "    \n",
    "first_agg = {\"Median Age\": \"first\", \"Male Population\": \"first\", \"Female Population\": \"first\", \n",
    "            \"Total Population\": \"first\", \"Number of Veterans\": \"first\", \"Foreign-born\": \"first\", \"Average Household Size\": \"first\"}\n",
    "\n",
    "# First aggregation - City\n",
    "agg_df = demographics.groupby([\"City\", \"State\", \"State Code\"]).agg(first_agg)\n",
    "\n",
    "# Pivot Table to transform values of the column Race to different columns\n",
    "piv_df = demographics.groupBy([\"City\", \"State\", \"State Code\"]).pivot(\"Race\").sum(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(City='Rockville', State='Maryland', State Code='MD', first(Total Population)=66998, first(Female Population)=35793, first(Median Age)=38.1, first(Number of Veterans)=1990, first(Foreign-born)=25047, first(Male Population)=31205, first(Average Household Size)=2.6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(City='Delray Beach', State='Florida', State Code='FL', American Indian and Alaska Native=None, Asian=1696, Black or African-American=21138, Hispanic or Latino=6397, White=40980)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename column names removing the spaces to avoid problems when saving to disk (we got errors when trying to save column names with spaces)\n",
    "demographics = agg_df.join(other=piv_df, on=[\"City\", \"State\", \"State Code\"], how=\"inner\")\\\n",
    "    .withColumnRenamed('State Code', 'StateCode')\\\n",
    "    .withColumnRenamed('first(Total Population)', 'TotalPopulation')\\\n",
    "    .withColumnRenamed('first(Female Population)', 'FemalePopulation')\\\n",
    "    .withColumnRenamed('first(Male Population)', 'MalePopulation')\\\n",
    "    .withColumnRenamed('first(Median Age)', 'MedianAge')\\\n",
    "    .withColumnRenamed('first(Number of Veterans)', 'NumberVeterans')\\\n",
    "    .withColumnRenamed('first(Foreign-born)', 'ForeignBorn')\\\n",
    "    .withColumnRenamed('first(Average Household Size)', 'AverageHouseholdSize')\\\n",
    "    .withColumnRenamed('Hispanic or Latino', 'HispanicOrLatino')\\\n",
    "    .withColumnRenamed('Black or African-American', 'BlackOrAfricanAmerican')\\\n",
    "    .withColumnRenamed('American Indian and Alaska Native', 'AmericanIndianAndAlaskaNative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- StateCode: string (nullable = true)\n",
      " |-- TotalPopulation: integer (nullable = true)\n",
      " |-- FemalePopulation: integer (nullable = true)\n",
      " |-- MedianAge: double (nullable = true)\n",
      " |-- NumberVeterans: integer (nullable = true)\n",
      " |-- ForeignBorn: integer (nullable = true)\n",
      " |-- MalePopulation: integer (nullable = true)\n",
      " |-- AverageHouseholdSize: double (nullable = true)\n",
      " |-- AmericanIndianAndAlaskaNative: long (nullable = true)\n",
      " |-- Asian: long (nullable = true)\n",
      " |-- BlackOrAfricanAmerican: long (nullable = true)\n",
      " |-- HispanicOrLatino: long (nullable = true)\n",
      " |-- White: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "numeric_cols = ['TotalPopulation', 'FemalePopulation', 'MedianAge', 'NumberVeterans', 'ForeignBorn', 'MalePopulation', \n",
    "                'AverageHouseholdSize', 'AmericanIndianAndAlaskaNative', 'Asian', 'BlackOrAfricanAmerican', 'HispanicOrLatino', 'White']\n",
    "\n",
    "# Fill the null values with 0\n",
    "demographics = demographics.fillna(0, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- StateCode: string (nullable = true)\n",
      " |-- TotalPopulation: integer (nullable = true)\n",
      " |-- FemalePopulation: integer (nullable = true)\n",
      " |-- MedianAge: double (nullable = false)\n",
      " |-- NumberVeterans: integer (nullable = true)\n",
      " |-- ForeignBorn: integer (nullable = true)\n",
      " |-- MalePopulation: integer (nullable = true)\n",
      " |-- AverageHouseholdSize: double (nullable = false)\n",
      " |-- AmericanIndianAndAlaskaNative: long (nullable = true)\n",
      " |-- Asian: long (nullable = true)\n",
      " |-- BlackOrAfricanAmerican: long (nullable = true)\n",
      " |-- HispanicOrLatino: long (nullable = true)\n",
      " |-- White: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now write (and overwrite) transformed `demographics` dataset onto parquet file\n",
    "# demographics.write.mode('overwrite').parquet(\"s3a://udacitycapstone-us-immigration-data-lake/us_cities_demographics.parquet\")\n",
    "demographics.write.mode('overwrite').parquet(\"us_cities_demographics.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read i94 immigration dataset\n",
    "immigration=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "int_cols = ['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', \n",
    "        'arrdate', 'i94mode', 'i94bir', 'i94visa', 'count', 'biryear', 'dtadfile', 'depdate']\n",
    "    \n",
    "date_cols = ['arrdate', 'depdate']\n",
    "    \n",
    "high_null = [\"visapost\", \"occup\", \"entdepu\", \"insnum\"]\n",
    "not_useful_cols = [\"count\", \"entdepa\", \"entdepd\", \"matflag\", \"dtaddto\", \"biryear\", \"admnum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert columns read as string/double to integer\n",
    "immigration = cast_type(immigration, dict(zip(int_cols, len(int_cols)*[IntegerType()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The date format string preferred to our work here: YYYY-MM-DD\n",
    "date_format = \"%Y-%m-%d\"\n",
    "convert_sas_udf = udf(lambda x: x if x is None else (timedelta(days=x) + datetime(1960, 1, 1)).strftime(date_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_sas_date(df, cols):\n",
    "    \"\"\"\n",
    "    Convert dates in the SAS datatype to a date in a string format YYYY-MM-DD\n",
    "    \n",
    "    Args:\n",
    "        df (:obj:`SparkDataFrame`): Spark dataframe to be processed. \n",
    "            Represents the entry point to programming Spark with the Dataset and DataFrame API.\n",
    "        cols (:obj:`list`): List of columns in the SAS date format to be convert\n",
    "    \"\"\"\n",
    "    for c in [c for c in cols if c in df.columns]:\n",
    "        df = df.withColumn(c, convert_sas_udf(df[c]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    " # Convert SAS date to a meaningful string date in the format of YYYY-MM-DD\n",
    "immigration = convert_sas_date(immigration, date_cols)\n",
    "    \n",
    "# Drop high null columns and not useful columns\n",
    "immigration = immigration.drop(*high_null)\n",
    "immigration = immigration.drop(*not_useful_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def date_diff(date1, date2):\n",
    "    '''\n",
    "    Calculates the difference in days between two dates\n",
    "    '''\n",
    "    if date2 is None:\n",
    "        return None\n",
    "    else:\n",
    "        a = datetime.strptime(date1, date_format)\n",
    "        b = datetime.strptime(date2, date_format)\n",
    "        delta = b - a\n",
    "        return delta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "date_diff_udf = udf(date_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a new columns to store the length of the visitor stay in the US\n",
    "immigration = immigration.withColumn('stay', date_diff_udf(immigration.arrdate, immigration.depdate))\n",
    "immigration = cast_type(immigration, {'stay': IntegerType()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- dtadfile: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- stay: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration.write.mode(\"overwrite\").parquet('immigration.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Start processing the I9I94_SAS_Labels_Description.SAS to create master i94 code dimensions:\n",
    "\n",
    "'''\n",
    "/* I94MODE - There are missing values as well as not reported (9) */\n",
    "\t1 = 'Air'\n",
    "\t2 = 'Sea'\n",
    "\t3 = 'Land'\n",
    "\t9 = 'Not reported' ;\n",
    "'''\n",
    "# Create i94mode list\n",
    "i94mode_data =[[1,'Air'],[2,'Sea'],[3,'Land'],[9,'Not reported']]\n",
    "\n",
    "# Convert to spark dataframe\n",
    "i94mode=spark.createDataFrame(i94mode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94mode.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create i94mode parquet file\n",
    "i94mode.write.mode(\"overwrite\").parquet('i94mode.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "countries = spark.read.format('csv').options(header='true', inferSchema='true').load(\"../../data2/GlobalLandTemperaturesByCity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Aggregates the dataset by Country and rename the name of new columns\n",
    "countries = countries.groupby([\"Country\"]).agg({\"AverageTemperature\": \"avg\", \"Latitude\": \"first\", \"Longitude\": \"first\"})\\\n",
    ".withColumnRenamed('avg(AverageTemperature)', 'Temperature')\\\n",
    ".withColumnRenamed('first(Latitude)', 'Latitude')\\\n",
    ".withColumnRenamed('first(Longitude)', 'Longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def change_field_value_condition(df, change_list):\n",
    "    '''\n",
    "    Helper function used to rename column values based on condition.\n",
    "    \n",
    "    Args:\n",
    "        df (:obj:`SparkDataFrame`): Spark dataframe to be processed.\n",
    "        change_list (:obj: `list`): List of tuples in the format (field, old value, new value)\n",
    "    '''\n",
    "    for field, old, new in change_list:\n",
    "        df = df.withColumn(field, when(df[field] == old, new).otherwise(df[field]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename specific country names to match the I94CIT_I94RES lookup table when joining them\n",
    "change_countries = [(\"Country\", \"Congo (Democratic Republic Of The)\", \"Congo\"), (\"Country\", \"CÃ´te D'Ivoire\", \"Ivory Coast\")]\n",
    "countries = change_field_value_condition(countries, change_countries)\n",
    "countries = countries.withColumn('CountryLower', lower(countries.Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "  # Rename specific country names to match the demographics dataset when joining them\n",
    "change_res = [(\"I94CTRY\", \"BOSNIA-HERZEGOVINA\", \"BOSNIA AND HERZEGOVINA\"), \n",
    "                  (\"I94CTRY\", \"INVALID: CANADA\", \"CANADA\"),\n",
    "                  (\"I94CTRY\", \"CHINA, PRC\", \"CHINA\"),\n",
    "                  (\"I94CTRY\", \"GUINEA-BISSAU\", \"GUINEA BISSAU\"),\n",
    "                  (\"I94CTRY\", \"INVALID: PUERTO RICO\", \"PUERTO RICO\"),\n",
    "                  (\"I94CTRY\", \"INVALID: UNITED STATES\", \"UNITED STATES\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loads the lookup table I94CIT_I94RES\n",
    "res = spark.read.format('csv').options(header='true', inferSchema='true').load(\"I94CIT_I94RES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "res = cast_type(res, {\"Code\": IntegerType()})\n",
    "res = change_field_value_condition(res, change_res)\n",
    "res = res.withColumn('resCountry_Lower', lower(res.I94CTRY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "capitalize_udf = udf(lambda x: x if x is None else x.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join the two datasets to create the country dimmension table\n",
    "res = res.join(countries, res.resCountry_Lower == countries.CountryLower, how=\"left\")\n",
    "res = res.withColumn(\"Country\", when(isnull(res[\"Country\"]), capitalize_udf(res.I94CTRY)).otherwise(res[\"Country\"]))   \n",
    "res = res.drop(\"I94CTRY\", \"CountryLower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Code: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = res.drop(\"resCountry_Lower\")\n",
    "res.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create i94mode parquet file\n",
    "res.write.mode(\"overwrite\").parquet('country.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+------+------+-------+----------+-------+-------+----------+------+-------+--------+------+-------+-----+--------+----+\n",
      "|  cicid|i94yr|i94mon|i94cit|i94res|i94port|   arrdate|i94mode|i94addr|   depdate|i94bir|i94visa|dtadfile|gender|airline|fltno|visatype|stay|\n",
      "+-------+-----+------+------+------+-------+----------+-------+-------+----------+------+-------+--------+------+-------+-----+--------+----+\n",
      "|5748517| 2016|     4|   245|   438|    LOS|2016-04-30|      1|     CA|2016-05-08|    40|      1|20160430|     F|     QF|00011|      B1|   8|\n",
      "|5748518| 2016|     4|   245|   438|    LOS|2016-04-30|      1|     NV|2016-05-17|    32|      1|20160430|     F|     VA|00007|      B1|  17|\n",
      "|5748519| 2016|     4|   245|   438|    LOS|2016-04-30|      1|     WA|2016-05-08|    29|      1|20160430|     M|     DL|00040|      B1|   8|\n",
      "+-------+-----+------+------+------+-------+----------+-------+-------+----------+------+-------+--------+------+-------+-----+--------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read i94 immigration dataset to create Date Frame\n",
    "i94_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "| 438.0|    LOS|20574.0|    1.0|20582.0|  40.0|    1.0|  1.0|     F|94953870030|\n",
      "| 438.0|    LOS|20574.0|    1.0|20591.0|  32.0|    1.0|  1.0|     F|94955622830|\n",
      "| 438.0|    LOS|20574.0|    1.0|20582.0|  29.0|    1.0|  1.0|     M|94956406530|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_spark.select(\"i94res\",\"i94port\",\"arrdate\",\"i94mode\",\"depdate\",\"i94bir\",\"i94visa\",\"count\" \\\n",
    "                  ,\"gender\",col(\"admnum\").cast(LongType())).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_spark=i94_spark.select(col(\"i94res\").cast(IntegerType()),col(\"i94port\"),\n",
    "                           col(\"arrdate\").cast(IntegerType()), \\\n",
    "                           col(\"i94mode\").cast(IntegerType()),col(\"depdate\").cast(IntegerType()),\n",
    "                           col(\"i94bir\").cast(IntegerType()),col(\"i94visa\").cast(IntegerType()), \n",
    "                           col(\"count\").cast(IntegerType()), \\\n",
    "                              \"gender\",col(\"admnum\").cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|   438|    LOS|  20574|      1|  20582|    40|      1|    1|     F|94953870030|\n",
      "|   438|    LOS|  20574|      1|  20591|    32|      1|    1|     F|94955622830|\n",
      "|   438|    LOS|  20574|      1|  20582|    29|      1|    1|     M|94956406530|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_spark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096313, 3096302)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_spark.count(), i94_spark.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3075579"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_spark.dropDuplicates(['admnum']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We will drop duplicate rows and save it as final dataset for i94\n",
    "i94_spark=i94_spark.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|   582|    XXX|  20557|   null|  20558|    34|      2|    1|  null|91904214530|\n",
      "|   209|    AGA|  20552|      1|   null|  null|      2|    1|     M|47842155333|\n",
      "|   209|    ATL|  20571|      1|   null|  null|      2|    1|     M|44537883633|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_spark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: integer (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- depdate: integer (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- admnum: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "# Convert SAS arrival date to datetime format\n",
    "get_date = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(x)).isoformat() if x else None)\n",
    "i94non_immigrant_port_entry = i94_spark.withColumn(\"arrival_date\", get_date(i94_spark.arrdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+------------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|arrival_date|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+------------+\n",
      "|   582|    XXX|  20557|   null|  20558|    34|      2|    1|  null|91904214530|  2016-04-13|\n",
      "|   209|    AGA|  20552|      1|   null|  null|      2|    1|     M|47842155333|  2016-04-08|\n",
      "|   209|    ATL|  20571|      1|   null|  null|      2|    1|     M|44537883633|  2016-04-27|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94non_immigrant_port_entry.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: integer (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- depdate: integer (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- admnum: long (nullable = true)\n",
      " |-- arrival_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94non_immigrant_port_entry.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "i94date= i94non_immigrant_port_entry.withColumn('Darrival_date',F.to_date(i94non_immigrant_port_entry.arrival_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: integer (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- depdate: integer (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- admnum: long (nullable = true)\n",
      " |-- arrival_date: string (nullable = true)\n",
      " |-- Darrival_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94date = i94date.withColumn('arrival_month',month(i94date.Darrival_date))\n",
    "i94date = i94date.withColumn('arrival_year',year(i94date.Darrival_date))\n",
    "i94date = i94date.withColumn('arrival_day',dayofmonth(i94date.Darrival_date))\n",
    "i94date = i94date.withColumn('day_of_week',dayofweek(i94date.Darrival_date))\n",
    "i94date = i94date.withColumn('arrival_weekofyear',weekofyear(i94date.Darrival_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: integer (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- depdate: integer (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- admnum: long (nullable = true)\n",
      " |-- arrival_date: string (nullable = true)\n",
      " |-- Darrival_date: date (nullable = true)\n",
      " |-- arrival_month: integer (nullable = true)\n",
      " |-- arrival_year: integer (nullable = true)\n",
      " |-- arrival_day: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- arrival_weekofyear: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94date=i94date.select(col('arrdate').alias('arrival_sasdate'),col('Darrival_date').alias('arrival_iso_date'),'arrival_month','day_of_week','arrival_year','arrival_day','arrival_weekofyear').dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create temporary sql table\n",
    "i94date.createOrReplaceTempView(\"i94date_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add seasons to i94 date dimension table\n",
    "i94date_season=spark.sql('''select arrival_sasdate,\n",
    "                         arrival_iso_date,\n",
    "                         arrival_month,\n",
    "                         day_of_week,\n",
    "                         arrival_year,\n",
    "                         arrival_day,\n",
    "                         arrival_weekofyear,\n",
    "                         CASE WHEN arrival_month IN (12, 1, 2) THEN 'winter' \n",
    "                                WHEN arrival_month IN (3, 4, 5) THEN 'spring' \n",
    "                                WHEN arrival_month IN (6, 7, 8) THEN 'summer' \n",
    "                                ELSE 'autumn' \n",
    "                         END AS date_season from i94date_table''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94date_season.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save i94date dimension to parquet file partitioned by year and month:\n",
    "i94date_season.write.mode(\"overwrite\").partitionBy(\"arrival_year\", \"arrival_month\").parquet('i94date.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
